Voir la section [2. Cr√©er un code python permettant de dialoguer avec sonnet 3.5](2-**cr√©er-un-code-python-permettant-de-dialoguer-avec-sonnet-3.5**)

__***Avec le monde d'avant l'IA on apprenait √† faire puis on faisait. Avec le monde d'aujourd'hui on fait faire √† l'IA, puis on apprend √† partir de ce que l'IA a fait, on finit donc par savoir faire aussi. Du coup plus besoin de prof, il ne suffit que de vouloir faire pour parvenir √† nos fins !! The sky is the limit !!!***__

**TO DO  ‚¨ú / DONE ‚úÖ** / en cours ‚öôÔ∏è
| Outils       | Briques de teambot       | TO DO  ‚¨ú |
|-------------------|-------------------|-------------------|
| - Prompting ‚úÖ| - Site web sur Github (7) ‚úÖ      | Traitement d'images |
| - Docker  ‚úÖ| - Simple API locale (1) ‚úÖ      | Speech to text via python |
| - Github ‚úÖ| - Programmation no code (AIDER) (4) ‚úÖ      |- Web scrapping via python ‚¨ú      |
| - GPT-4o ‚úÖ| -  LLM api en local (LM Studio)       |- RAG via python ‚¨ú      |
| - Anthropic chat & API (Sonnet 3.5) ‚úÖ| - Text to speech via python   ‚úÖ     |-  GPTs    |
| - Perplexity   ‚úÖ|- Text to vid√©o via python (3)    ‚úÖ       |-  Agents    |
| - Comfyui   ‚úÖ| - Tutoriel video automatique     |- Function calling (Gorilla)    |
| - Copilot ‚úÖ| -  Cr√©ation d'images consistantes  ‚úÖ    |- Text to CAD (9) ‚öôÔ∏è      |
| - Anaconda ‚úÖ| - Cr√©ation de tutoriel vid√©o  ‚úÖ       |- Serveur local     |
| - Hedra ‚úÖ | - Vid√©o-livre narratif g√©n√©r√© √† partir de texte (8) ‚öôÔ∏è     |- Remote PC (Kaggle)     |
| - Mistral| - LLM via python (2)  ‚úÖ      |-  LLM en //     |
| - Deepseek | - Text to image local (6)   ‚úÖ     |-  Open interpreter ‚¨ú  |
|- [Groq](https://groq.com/) ‚úÖ |-   |-   |
# AI-automation
Tout faire avec l'IA. Elle fait le boulot sous votre contr√¥le et vous forme √† comprendre comment tout √ßa fonctionne.

L'id√©e est de construire pas √† pas une "baquette magique" apte √† tout faire. Nous nous bornerons √† vous indiquer:
- Les bons outils √† utiliser,
- Comment bien poser votre probl√®me
- Comment apprendre cette nouvelle fa√ßon de travailler , en comprenant comment la magie op√©re.



## Les incontournables utilisables sans rien automatiser. 

- [Mieux vaut regarder les benchmarks pour choisir](https://klu.ai/glossary/mmlu-pro-eval)
<img src="https://github.com/jpbrasile/AI-automation/assets/8331027/57f69c6d-9505-4b23-82a7-eee9025e392e" width="600" />




- Donc utiliser **Sonnet 3.5** et **GPT-4o** pour avoir les meilleures r√©ponses √† nos questions.
- [**Perplexity**](https://www.perplexity.ai/) est un autre incontournable pour surfer sur le web ( que nous contournerons quand m√™me plus tard ! üòä)
- [**Harpa**](Harpa.ai) permet d'interagir avec une page web ou une video YouTube
- **Copilot de Microsoft**
- Je vous laisse le soin de tester ces diff√©rents logiciels qui m√™me dans leurs versions gratuites am√©lioreront sensiblement votre productivit√©.

## Les incontournables pour automatiser:
- Les m√™mes (ou leur √©quivalent) accessibles √† l'int√©rieur d'un code Python. 
- Des outils produisant et mettant en oeuvre le code √† notre place
- Des outils pour produire automatiquement des vid√©os qui nous servirons √† apprendre ce que fait l'IA
- Des outils pour [appeler des fonctions externes](https://gorilla.cs.berkeley.edu/leaderboard.html)
<img src="https://github.com/jpbrasile/AI-automation/assets/8331027/084708bc-b8f1-469e-94bd-32d48cc6cf50" width="600" />

## Architecture g√©n√©rale:
<img src="https://github.com/jpbrasile/AI-automation/assets/8331027/17a47369-f026-46b6-a11c-0dc0d48f35de" width="600" />

- Le coeur du syst√®me, les **LLM** (Large language model)  recoivent du texte, le traite et fournissent du texte en retour. Le texte d'entr√©e doit √™tre tel qu'il exprime clairement et concr√®tement nos attentes (c'est le prompting)
- Le texte en retour peut √™tre format√© pour correspondre √† une r√©ponse de type texte brut, JSON,  markdown, HTML , code , API ... suivant le post processing envisag√©.

1. ## Cr√©ation automatique d'une API web qui peut effectuer deux op√©rations math√©matiques :

- Additionner deux nombres
- Multiplier deux nombres

- L'application doit √™tre conteneuris√©e avec Docker pour faciliter son d√©ploiement et son ex√©cution.
- Vous voulez un guide √©tape par √©tape pour cr√©er cette application, en partant de z√©ro, sans aucun outil pr√©install√© sur votre ordinateur.
- L'objectif final est de pouvoir non seulement cr√©er cette application, mais aussi de pouvoir la partager facilement. 
- Vous voulez que n'importe qui puisse la t√©l√©charger et la lancer sur son propre ordinateur, quelle que soit sa configuration.
- Vous avez besoin d'instructions claires sur comment lancer l'application et comment la reproduire sur un autre PC.
- [**Dialogue avec sonnet 3.5** pour mettre en oeuvre la solution en "manuel"](https://claude.ai/chat/a71daeb6-5875-4ecb-9dc6-7dce126afde0) 
- Nous verrons plus tard comment automatiser la mise en plac de ce type d'application en automatique avec AIDER
  
## Faisons le tutoriel correspondant sous forme de vid√©o
- L'id√©e est de partir de la synth√®se r√©capitul√©e par sonnet 3.5 de notre programme pr√©c√©dent pour en faire un tuto.
- Pour cela on √©tablit un [dialogue avec sonnet 3.5](https://claude.ai/chat/08fb3cc8-5cb4-45ed-9132-953e30ecf792) pour d√©grossir le probl√®me:
    - Pour cr√©er les planches HTML support,
    - Le texte des voice over,
    - Le prompt pour produire les images
    - Le code python pour stocker ces donn√©es dans des r√©pertoires
    - Le code python cr√©ant les MP3 et les images et qui les stockent
    - Le code python qui fait l'assemblage
- Ce d√©grossissage montre qu'il est pr√©f√©rable d'avancer pas √† pas en construisant et validant pas √† pas le code python correspondant, ce que nous allons faire maintenant avec un nouveau thread sonnet 3.5.
2. **Cr√©er un code python permettant de dialoguer avec sonnet 3.5**
  - On utilisera Visual Studio Code pour la mise en oeuvre et pour tester les codes
  - On utilisera anaconda pour cr√©er un environnement logiciel sp√©cifique. Nous utiliserons l'environnement teambot d√©j√† cr√©er avec `conda activate teambot` dans un terminal 
  - On cr√©e un r√©pertoire de travail video-maker dans lequel on met le fichier .env avec nos clefs API, ainsi que les fichiers requirements.txt et anthropic-api-hello-world.py cr√©er par sonnet 3.5
  - Le dialogue fonctionne :
    
```bash
(base) PS C:\Users\test\Documents\AI_Automation\video_maker> conda activate teambot

(teambot) PS C:\Users\test\Documents\AI_Automation\video_maker> python anthropic-api-hello-world.py
Claude dit: [TextBlock(text='Bonjour !', type='text')]
```

3. [**Cr√©ation d'une vid√©o √† partir d'un texte**](https://claude.ai/chat/c33dece9-e5ab-4206-98c6-de644cb1d731)  
- Ce projet automatise la cr√©ation de vid√©os √©ducatives √† partir de contenu textuel, utilisant diverses technologies et APIs. Le processus se d√©roule en plusieurs √©tapes int√©gr√©es dans un script Python unique :
  - Conversion du texte :
    - Lit le contenu du fichier PLACE_HOLDER_TEXTE_VIDEO.txt.
    - Utilise l'API Claude d'Anthropic pour convertir le texte en structure JSON de diapositives.
  - Traitement des diapositives :
    - G√©n√®re un fichier HTML structur√© avec CSS int√©gr√© pour chaque diapositive.
    - Cr√©e un texte de voix off avec Claude.
    - Produit une image illustrative via l'API DALL-E d'OpenAI.
    - G√©n√®re un fichier audio de la voix off avec l'API Text-to-Speech d'OpenAI.
  - Cr√©ation des vid√©os :
    - Capture une image du HTML rendu avec Selenium.
    - Combine l'image et l'audio en utilisant MoviePy pour chaque diapositive.
  - Agr√©gation finale :
    - Assemble toutes les vid√©os individuelles en une seule vid√©o.
    - Ajoute des transitions entre les diapositives.

Le projet utilise Python avec diverses biblioth√®ques (BeautifulSoup, Requests, Pillow, MoviePy) et APIs (Anthropic, OpenAI). Cette approche int√©gr√©e offre une solution compl√®te et efficace pour la production automatis√©e de contenu vid√©o √©ducatif, de la conversion du texte √† la cr√©ation de la vid√©o finale.

4. **Point d'√©tape:**
- Nous avons r√©ussi √† mettre en oeuvre une applicatoin complexe sans coder une seule ligne. Cependant ce faisant nous avons d√©tect√© des pistes pour augmenter encore notre productivit√©
  - **Automatiser les it√©rations de d√©buggage** , ce qui nous a fait perdre le plus de temps dans la mise au point du code
  - Passer √† l'open source, en particulier pour la cr√©ation d'image qui constitue le poste de d√©pense le plus √©lev√© pour la cr√©ation d'une vid√©o
  - Faire du web scraping pour voir si notre probl√®me n'est pas d√©j√† r√©solu par ailleurs
 
5. **Coding assistant: AIDER+Sonnet**
- On cr√©e le r√©pertoire ```coding_assistant``` et on lance ```conda activate teambot```
- On suit les [instructions d'installation](https://github.com/paul-gauthier/aider) 
- Mais il faut l'adapter au terminal powershell :```$env:ANTHROPIC_API_KEY="sk... "```
- AIDER r√©pond √† nos directives et adapte en cons√©quence un repository qui a √©t√© clon√© localement.
- Il conserve un logbook des actions entreprises (```.aider.chat.history.md```) et un LLM comme Sonnet 3.5 ou GPT-4o peut alors en faire la synth√®se:
  ```J'ai eu des probl√®mes qui ont √©t√© r√©solu dans le document joint, fais en la synth√®se```

6. [**Text to image local dans docker**](https://claude.ai/chat/f8d04905-3570-4f00-b7e9-f220936ff540)
- Il faut "alimenter" comfyui en y rajoutant les chkpoints requis √† placer dans le r√©pertoire : ```C:\Users\test\Documents\AI_Automation\coding_assistant\comfyui\storage\ComfyUI\models\checkpoints```
- Il n'y a pas de consensus clair sur un seul ¬´ meilleur ¬ª point de contr√¥le pour ComfyUI, car cela d√©pend beaucoup de vos pr√©f√©rences personnelles et du type d'image que l'on souhaite g√©n√©rer. Cependant, plusieurs points de contr√¥le sont fr√©quemment recommand√©s pour leur qualit√© :
  - SDXL (Stable Diffusion XL) : C'est un mod√®le de base tr√®s performant, particuli√®rement bon pour le r√©alisme et la qualit√© g√©n√©rale des images.
  - Juggernaut XL : Souvent cit√© comme l'un des meilleurs pour le photor√©alisme
  - Dreamshaper : Appr√©ci√© pour sa polyvalence et sa qualit√©, particuli√®rement dans sa version Turbo
  - Vision r√©aliste : Excellent pour g√©n√©rer des humains r√©alistes.
  - RealVis XL : √âgalement recommand√© pour le photor√©alisme
- La g√©n√©ration d'images peut se faire via une requ√™te API comme le montre  [basic_api_exemple.py](https://claude.ai/chat/f8d04905-3570-4f00-b7e9-f220936ff540)
7. [**Cr√©er son site en ligne avec Github**:

Pour mettre en place un site personnel avec GitHub Pages, voici les √©tapes que vous devez suivre :

1. [**Cr√©ez un compte GitHub** :]([https://chatgpt.com/c/2a5fd138-49c0-42bb-a057-a831e6dbc5ea](https://chatgpt.com/c/37b0d84b-d7bd-4455-b5ae-44082f81226c))
- Il faut cr√©er un d√©pot public sur Github
- Cr√©ez un fichier `index.html` avec un contenu ```<html><head><title>Mon Site</title></head><body><h1>Bonjour Monde JPB !</h1></body></html>```
- Le cloner en local ```git clone https://github.com/jpbrasile/github.io```
- **Publiez vos modifications** :
     - Ajoutez les fichiers modifi√©s √† votre d√©p√¥t :
       ```
       git add --all
       ```
     - Faites un commit des modifications :
       ```
       git commit -m "Initial commit"
       ```
     - Poussez les modifications sur GitHub :
       ```
       git push -u origin main
       ```
  - Il faut faire "sign in with a code" pour parvenir √† valider le push
    
  Une fois ces √©tapes termin√©es, votre site sera en ligne √† l'adresse [https://username.github.io/github.io/](https://jpbrasile.github.io/github.io/).

  8- **Cr√©er un story teller automatique**
- La premi√®re √©tape consiste √† produire des images consistantes afin que les personnages ou objets reproduits sur plusieurs diapositives soient quasi-identiques:
  - Nous avons cr√©√© un "m√©ta-prompt" qui √† partir d'un descriptif simple <situation> fournit des images consistantes:
  - M√©ta-prompt:

```
Prompt_Structure:
{scene_setting}. {entity1_name} ({entity1_traits}) {action1} {object1_name} ({object1_traits}). {entity2_name} ({entity2_traits}) {action2}. {atmosphere}

Definitions:
- scene_setting: Brief description of location and context
- entity1_name: Identifier for the first entity (e.g., man_1, woman_1, dog_1)
- entity1_traits: age, physical_appearance, clothing
- action1: Main action of entity1
- object1_name: Identifier for the main object (e.g., watch_1, map_1)
- object1_traits: material, distinctive_features, size
- entity2_name: Identifier for the second entity
- entity2_traits: age, physical_appearance, clothing/characteristics
- action2: Main action of entity2
- atmosphere: General ambiance and shared activity

Instructions:
1. Replace each element with specific details consistent with the provided <situation>.
2. Maintain coherence between entities, their actions, and the context.
3. Use unique identifiers for entities and objects to facilitate reference and reuse.

Example:
Cafe_table_1 in a bustling coffee shop. Man_1 (25 years old, short brown hair, white shirt and blue jeans) carefully examines Watch_1 (antique gold, floral engravings, normal size). Woman_1 (70 years old, gray hair in a bun, red floral dress and round glasses) leans forward with interest. They are absorbed in their animated conversation.
```
- Sonnet a r√©alis√© le prompt sp√©cifique √† partir de ```<situation> A man walking his dog in the forest```
```
Forest_trail_1 in a lush, shadowy woodland with dappled sunlight. Man_1 (45 years old, salt-and-pepper hair, rugged stubble, green waterproof jacket and khaki hiking pants) studies Map_1 (weatherproof paper, colorful trail markings, slightly creased) while striding purposefully. Dog_1 (6 years old, German Shepherd, glossy black and tan coat, red nylon collar with tags) trots eagerly ahead, nose twitching at the scent of pine and earth. They are enveloped in a serene atmosphere of natural exploration, with a gentle breeze rustling through the canopy above.
``` 
  - Voil√† le r√©sultat fournit par copilot pour la cr√©ation d'image avec copilot:
![image](https://github.com/jpbrasile/AI-automation/assets/8331027/497bf3b4-b95d-451a-8775-1c99a2f5ac5d)
  - et avec leonardo.ai (qui oublit la carte et met le "collier rouge" sur le vieil homme) :
![image](https://github.com/jpbrasile/AI-automation/assets/8331027/ed959f12-0774-472a-950f-e810baa0c861)



  - La deuxi√®me √©tape consiste √† avoir le script de la vid√©o, c'est √† dire tous les √©l√©ments textuels qui permettront la cr√©ation automatique de la vid√©o.  


9. **Text to CAD**
- Sonnet 3.5 semble √™tre capable de cr√©er un [programme python capable de g√©n√©rer des formes complexes](https://claude.ai/chat/91026ba9-f74b-4622-b215-3148ada38543)
-  Par ailleurs [CadQuery](https://github.com/CadQuery/cadquery) semble int√©ressant √† √©valuer 
üõ†Ô∏è CadQuery : Module Python intuitif pour cr√©er des mod√®les param√©triques 3D.
‚úçÔ∏è Scripts courts : √âcrire des scripts simples pour produire des mod√®les de haute qualit√©.
üÜö Comparaison OpenSCAD :
üìú Utilise Python : Acc√®s √† de nombreuses biblioth√®ques et IDE.
üîß Noyau OCCT : Plus puissant que CGAL, supporte NURBS, splines, import/export STEP.
‚è±Ô∏è Scripts concis : Moins de code n√©cessaire gr√¢ce √† des fonctionnalit√©s de positionnement avanc√©es.
üöÄ G√©n√©ration rapide : Cr√©e des fichiers STL, STEP, AMF et 3MF plus rapidement.
üíª Int√©gration facile : Con√ßu comme biblioth√®que Python sans GUI, id√©al pour serveurs et scripts scientifiques.
üõ°Ô∏è Avantages :
üîÑ Mod√®les param√©triques facilement personnalisables.
üñ®Ô∏è Sortie de formats CAD de haute qualit√© (STEP, DXF, etc.).
üß© Assemblages imbriqu√©s √† partir de pi√®ces individuelles.
üöÄ Version 2.0 :
üîÑ Bas√©e sur OCCT : Plus de contr√¥le et de flexibilit√©, malgr√© une complexit√© accrue.
